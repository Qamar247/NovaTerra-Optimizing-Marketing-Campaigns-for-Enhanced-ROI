{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "04240eb9",
      "metadata": {
        "id": "04240eb9"
      },
      "source": [
        "# **Optimizing Marketing Campaigns for Enhanced ROI: A Data-Driven Approach**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Executive Summary**\n",
        "\n",
        "**Purpose:** This project analyzes **marketing campaign data** for **\"NovaTerra\"** to identify **key drivers of success** and proposes **data-driven solutions** to **improve campaign performance**, ultimately optimizing marketing strategies and **maximizing ROI**.\n",
        "\n",
        "**Methodology:** Leveraging a dataset of customer demographics, purchasing behavior, and campaign responses, the analysis involved data cleaning, exploratory data analysis, customer segmentation using RFM analysis, and predictive modeling with a Random Forest Classifier. Channel performance and product recommendations were also investigated.\n",
        "\n",
        "**Key Findings:**\n",
        "\n",
        "  * High-value and loyal customer segments demonstrate the strongest response rates to marketing campaigns.\n",
        "  \n",
        "  * Store and web channels prove most effective in reaching and engaging these valuable segments.\n",
        "\n",
        "  * Campaigns Cmp3 and Cmp5 demonstrate significant success in driving customer response.\n",
        "\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "* Personalize marketing campaigns to target high-value and loyal customer segments.\n",
        "\n",
        "* Prioritize marketing efforts on store and web channels.\n",
        "\n",
        "* Continue to leverage successful campaign strategies from Cmp3 and Cmp5.\n",
        "\n",
        "* Implement product recommendation strategies based on frequent itemsets.\n",
        "\n",
        "This analysis provides actionable insights to guide marketing investments and drive growth. By optimizing strategies to acquire and retain valuable customers, the business can significantly boost profitability.\n",
        "\n"
      ],
      "metadata": {
        "id": "bDeWRT17IQLq"
      },
      "id": "bDeWRT17IQLq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction**\n",
        "\n",
        "* In today's competitive market, businesses constantly seek ways to optimize their marketing efforts and maximize return on investment (ROI).\n",
        "\n",
        "* This project delves into the effectiveness of marketing campaigns by leveraging data analysis to identify key drivers of success and propose data-driven solutions for improvement.\n"
      ],
      "metadata": {
        "id": "b7rt1M3PK-9N"
      },
      "id": "b7rt1M3PK-9N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **i. Problem Statement**\n",
        "\n",
        "* Our client is facing challenges in achieving the desired results from their current marketing campaigns, leading to potentially **lower conversion rates** and **reduced ROI**.\n",
        "\n",
        "* This project aims to address this **problem** by conducting a comprehensive data analysis to identify the underlying factors contributing to **campaign ineffectiveness** and **propose data-driven solutions** for improvement.\n",
        "\n",
        "\n",
        "## **ii. Business Context**\n",
        "\n",
        "* In today's competitive market, effective marketing campaigns are crucial for business growth and profitability.\n",
        "\n",
        "* **Poorly performing campaigns can lead to significant financial losses and missed opportunities for customer acquisition.**\n",
        "\n",
        "* This project emphasizes data-driven decision-making as a key strategy for **optimizing marketing investments** and ensuring alignment with business objectives.\n",
        "\n",
        "\n",
        "\n",
        "## **iii. Project Objective**\n",
        "\n",
        "* The objective of this project is to leverage data analytics to **identify key drivers of campaign effectiveness**, uncover areas for improvement, and **propose data-driven strategies to optimize future marketing efforts**.\n",
        "\n",
        "* This includes **analyzing customer segmentation, channel performance, product preferences, and campaign response patterns to deliver actionable recommendations for maximizing ROI**.\n",
        "\n",
        "* The outcomes of this project will be presented in a comprehensive report to the Senior Marketing Manager.\n",
        "\n",
        "\n",
        "## **iv. Methodology**\n",
        "\n",
        "* This project will involve data cleaning, exploratory data analysis, customer segmentation, predictive modeling, evaluation of campaign performance metrics and Key findings and recommendations."
      ],
      "metadata": {
        "id": "xh8lc6Xzgzks"
      },
      "id": "xh8lc6Xzgzks"
    },
    {
      "cell_type": "markdown",
      "id": "c22a67a5",
      "metadata": {
        "id": "c22a67a5"
      },
      "source": [
        "## **Data Analysis Plan**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d5a8d5",
      "metadata": {
        "id": "76d5a8d5"
      },
      "source": [
        "1. **Data Cleaning:** correct data types, Handle missing values and remove duplicates.\n",
        "\n",
        "2.  **Exploratory Data Analysis (EDA):** Understand the data distribution, identify patterns, and visualize key insights.\n",
        "\n",
        "3.  **Feature Engineering:** Create new features that might help improve the model's performance.\n",
        "\n",
        "4.  **Model Building:** Build and evaluate different models to find the best one for predicting campaign effectiveness.\n",
        "\n",
        "5. **Proposed Solutions:** Based on the analysis, propose data-driven solutions to improve marketing campaign effectiveness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c53a33f",
      "metadata": {
        "id": "0c53a33f"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888b8fd0",
      "metadata": {
        "id": "888b8fd0"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for the analysis\n",
        "\n",
        "# Working with arrays\n",
        "import numpy as np\n",
        "\n",
        "# Data analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install plotly\n",
        "!pip install plotly --upgrade\n",
        "import plotly.express as px\n",
        "\n",
        "# To avoid warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning, module='_plotly_utils')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea4614b",
      "metadata": {
        "id": "fea4614b"
      },
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19342cd5",
      "metadata": {
        "scrolled": true,
        "id": "19342cd5"
      },
      "outputs": [],
      "source": [
        "#dataset available in Github repo.\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Qamar247/Marketing-Campaign-Effectiveness-Analysis/refs/heads/main/marketing_data_analytics.csv\")\n",
        "\n",
        "\n",
        "# Displaying rows of the dataset\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae13cf2",
      "metadata": {
        "id": "cae13cf2"
      },
      "source": [
        "## **1. Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665c18ae",
      "metadata": {
        "id": "665c18ae"
      },
      "source": [
        "* Find and replace missinng values. One of the most important step in building EDA pipelines.\n",
        "\n",
        "* e.g. The main task/goal of data scientisit is Data cleaning. If there are some missing values and we train our model it will not give us accurate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1f0b6bf",
      "metadata": {
        "id": "e1f0b6bf"
      },
      "outputs": [],
      "source": [
        "#checking data types of columns always before data cleaning.\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf669f85",
      "metadata": {
        "id": "cf669f85"
      },
      "outputs": [],
      "source": [
        "# To ensure that the \"Income\" column is treated as a string, we need to explicitly convert it to a string type before performing string operations.\n",
        "\n",
        "# Renamed column to remove leading/trailing spaces\n",
        "df.rename(columns={' Income ': 'Income'}, inplace=True)\n",
        "\n",
        "# Ensured all values in 'Income' column are strings\n",
        "df['Income'] = df['Income'].astype(str)\n",
        "\n",
        "# Removed the dollar sign and commas, then convert to float\n",
        "df['Income'] = df['Income'].str.replace(\"$\", \"\")\n",
        "df['Income'] = df['Income'].str.replace(\",\", \"\")\n",
        "df['Income'] = df['Income'].astype(float)\n",
        "\n",
        "# Verifying changes\n",
        "df['Income'].head()\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7bb78a",
      "metadata": {
        "id": "af7bb78a"
      },
      "outputs": [],
      "source": [
        "### Finding missing values\n",
        "df.isna().sum()\n",
        "\n",
        "\n",
        "# both are the smme way to chek missing values.\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b07e90b",
      "metadata": {
        "id": "1b07e90b"
      },
      "source": [
        " *  \"INCOME Column\" might provide us insights into, how income levels affect the response to \"marketing campaigns\"(target variable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69625ef",
      "metadata": {
        "id": "e69625ef",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Before filling the missing values we need to check the distribution of the data.\n",
        "# then we will deicde either we impute the missing values with \"mean[if the data is normally distributed] or median[ if the data is skewed or contains outliers]\".\n",
        "\n",
        "# To decide which one to use, we visualize the distribution of \"Income\"\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(df, x=\"Income\", title=\"Income Distribution\",\n",
        "                   nbins=10, marginal=\"rug\",\n",
        "                   color_discrete_sequence=['#636EFA']) # Optional: Customize color\n",
        "fig.update_layout(xaxis_title=\"Income\", yaxis_title=\"Frequency\")\n",
        "fig.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab92858",
      "metadata": {
        "id": "eab92858"
      },
      "outputs": [],
      "source": [
        "# From the  above chart, we can see that the data is skewed to the right. Therefore, we will use the median to fill in the missing values.\n",
        "\n",
        " # Using median to impute missing values in column 'Income'\n",
        "df['Income'].fillna(df['Income'].median(), inplace=True)\n",
        "\n",
        "#verifying if any row is left with missing values.\n",
        "df['Income'].isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c1908f",
      "metadata": {
        "id": "e3c1908f"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicates\n",
        "df.duplicated().sum()\n",
        "df.drop_duplicates(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07acac56",
      "metadata": {
        "id": "07acac56"
      },
      "outputs": [],
      "source": [
        "# No douplicates found in dataset because the number of rows are same.\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df20d0fe",
      "metadata": {
        "id": "df20d0fe"
      },
      "source": [
        "### **Key Information**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1368c7e0",
      "metadata": {
        "id": "1368c7e0"
      },
      "source": [
        "*  **\"Response\"** is the Target Column for our Analysis.\n",
        "\n",
        "*  This column indicates whether a customer responded positively to a marketing campaign (coded as 1 for +ve response & 0 for no response).\n",
        "\n",
        "*  It serves as the primary measure of \"campaign effectiveness\".\n",
        "\n",
        "*  Analyzing this column will help determine which factors (such as income, age, spending on products, etc.) influence customer responses to marketing efforts.\n",
        "\n",
        "*  It allows for the evaluation of the success of different marketing strategies and campaigns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9358284d",
      "metadata": {
        "id": "9358284d"
      },
      "source": [
        "## **2.Exploratory Data Analysis (EDA)**\n",
        "\n",
        "* Summary statistics and visualizations to understand the distribution of data.\n",
        "* Key insights about customer demographics and spending behavior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f3d024e",
      "metadata": {
        "id": "7f3d024e"
      },
      "source": [
        "1. Now we visualize all numerical columns to understand their distributions, then we identify any potential outliers, and observe relationships between different variables.\n",
        "\n",
        "2. This helps us in gaining insights into our data and making informed decisions during the \"data preprocessing and feature engineering\" stages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4e2f5b",
      "metadata": {
        "id": "ef4e2f5b"
      },
      "outputs": [],
      "source": [
        "# Summary stats of \"nummerical columns\"\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c47625",
      "metadata": {
        "collapsed": true,
        "id": "f9c47625"
      },
      "outputs": [],
      "source": [
        "# Visualizing data distributions for all \"numerical columns\"\n",
        "# then we select only relevant columns for further analysis.\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.renderers.default = 'colab'  # default renderer\n",
        "\n",
        "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "for column in numerical_columns:\n",
        "    fig = px.histogram(df, x=column, title=f'Distribution of {column}',\n",
        "                       nbins=15, marginal=\"rug\", color_discrete_sequence=['#636EFA'])\n",
        "    fig.update_layout(xaxis_title=column, yaxis_title=\"Frequency\")\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42a6823e",
      "metadata": {
        "id": "42a6823e"
      },
      "source": [
        "We will drop these 2 \"numerical columns ('Kidhome', 'Teenhome) then continue our further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical columns to drop\n",
        "numerical_columns_to_drop = [\n",
        "    'Kidhome',\n",
        "    'Teenhome',\n",
        "]"
      ],
      "metadata": {
        "id": "O9WxqDoBMbLe"
      },
      "id": "O9WxqDoBMbLe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. **Recency** -- can help to assess customer engagement and the effectiveness of recent marketing campaigns.\n",
        "\n",
        " 2. **Income** -- customer income levels can provide insights into spending behavior and target marketing strategies effectively.\n",
        "\n",
        " 3. **MntWines, MntFruits, MntMeatProducts, MntFishProducts, MntSweetProducts, MntGoldProds** -- amount spent on different product categories.    Analyzing these can help us identify which products are most profitable and how they relate to campaign effectiveness.\n",
        "\n",
        " 4. **NumWebPurchases, NumCatalogPurchases, NumStorePurchases** -- number of purchases made through different channels. Understanding channel performance can inform marketing strategies.\n",
        "\n",
        " 5. **NumWebVisitsMonth** -- how often customers visit the website, which can correlate with campaign effectiveness and customer interest.\n",
        "\n",
        " 6. **AcceptedCmp1, AcceptedCmp2, AcceptedCmp3, AcceptedCmp4, AcceptedCmp5** -- whether customers accepted various campaigns. Analyzing acceptance rates can help us evaluate the success of each campaign.\n",
        "\n",
        " 7. **Complain** -- Understanding customer complaints that can provide insights into areas needing improvement in marketing strategies.\n",
        "\n",
        " 8. **Response** target column -- whether a customer responded positively to a campaign. Crucial for measuring campaign effectiveness.\n"
      ],
      "metadata": {
        "id": "tezJ9xcMLlUE"
      },
      "id": "tezJ9xcMLlUE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * Keeping these numerical columns will allow us for a comprehensive analysis of customer behavior, spending patterns, and the effectiveness of marketing campaigns.\n",
        "\n",
        "  * This data we use to derive actionable insights and improve future marketing strategies."
      ],
      "metadata": {
        "id": "u6lepkQcMTPs"
      },
      "id": "u6lepkQcMTPs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6036cdb9",
      "metadata": {
        "id": "6036cdb9"
      },
      "outputs": [],
      "source": [
        "# Keeping only \"necessary numerical and all categorical columns\"\n",
        "df_filtered = df.drop(columns=numerical_columns_to_drop)\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "df_filtered.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceCY6zEJEHxL"
      },
      "outputs": [],
      "source": [
        "# Summary stats for \"categorical columns\"\n",
        "df.describe(include=[object])\n"
      ],
      "id": "ceCY6zEJEHxL"
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning, module='_plotly_utils')\n",
        "\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "# List of categorical columns to visualize\n",
        "categorical_columns = ['Education', 'Marital_Status', 'Dt_Customer', 'Country']\n",
        "\n",
        "# Visualizing data distributions for categorical columns\n",
        "for column in categorical_columns:\n",
        "    fig = px.bar(df_filtered, x=column, title=f'Distribution of {column}',\n",
        "                 color_discrete_sequence=['#008060'])  # Darker green color\n",
        "\n",
        "    # Special handling for Dt_Customer to improve x-axis label display\n",
        "    if column == 'Dt_Customer':\n",
        "        fig.update_layout(\n",
        "            xaxis_title='Dt_Customer',\n",
        "            yaxis_title=\"Count\",\n",
        "            xaxis={'categoryorder': 'total descending', 'tickangle': -45,\n",
        "                   'tickfont': {'size': 10}},\n",
        "            autosize=False,\n",
        "            width=1000\n",
        "        )\n",
        "    else:\n",
        "        fig.update_layout(xaxis_title=column, yaxis_title=\"Count\", xaxis={'categoryorder':'total descending'})\n",
        "\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "nX0WdCV5e4NO"
      },
      "id": "nX0WdCV5e4NO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "619b1e24",
      "metadata": {
        "id": "619b1e24"
      },
      "source": [
        "## **Now i want to Visualize relationships between variables**\n",
        "\n",
        "* Visualizing relationships between \"numerical and categorical variables\" is crucial for understanding how different factors interact with each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Tz3LItEHxL"
      },
      "outputs": [],
      "source": [
        "# Box plot: Income distribution by Education level\n",
        "fig = px.box(df_filtered, x='Education', y='Income', title='Income Distribution by Education Level',\n",
        "             color_discrete_sequence=['#636EFA'])  # Optional: Customize color\n",
        "fig.update_layout(xaxis_title='Education Level', yaxis_title='Income')\n",
        "fig.show()\n"
      ],
      "id": "R8Tz3LItEHxL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb9cc27",
      "metadata": {
        "id": "abb9cc27"
      },
      "outputs": [],
      "source": [
        "# Pair plot: Relationships between numerical variables\n",
        "fig = px.scatter_matrix(df_filtered, dimensions=[\"Income\", \"MntWines\", \"MntMeatProducts\"],\n",
        "                        title=\"Relationships between Numerical Variables\",\n",
        "                        color_discrete_sequence=px.colors.qualitative.Set1)  # Optional: Customize colors\n",
        "fig.update_traces(diagonal_visible=False)  # Hide diagonal histograms\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(df_filtered, x=\"Income\", y=\"MntWines\",\n",
        "                 title=\"Relationships between Numerical Variables\",\n",
        "                 color_discrete_sequence=px.colors.qualitative.Set1)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Hsn8ljfw9V40"
      },
      "id": "Hsn8ljfw9V40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e2d525",
      "metadata": {
        "id": "02e2d525"
      },
      "outputs": [],
      "source": [
        "# Heatmap: Correlation matrix of numerical variables\n",
        "correlation_matrix = df_filtered[['Income', 'MntWines', 'MntMeatProducts']].corr()\n",
        "\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                x=correlation_matrix.columns,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='RdBu_r',\n",
        "                title='Correlation Matrix of Numerical Variables',\n",
        "                text_auto=True  # to enable text labels\n",
        "               )\n",
        "fig.update_layout(\n",
        "    xaxis_title='',\n",
        "    yaxis_title=''\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c1d69b",
      "metadata": {
        "id": "d2c1d69b"
      },
      "outputs": [],
      "source": [
        "# 1. Distribution of Income\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(df_filtered, x=\"Income\", title=\"Income Distribution\",\n",
        "                   nbins=20, marginal=\"rug\",\n",
        "                   color_discrete_sequence=['#636EFA'])\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Income\",\n",
        "    yaxis_title=\"Frequency\"\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "# 2. Distribution of Age\n",
        "fig = px.histogram(df_filtered, x=\"Year_Birth\", title=\"Year of Birth Distribution\",\n",
        "                   nbins=20, marginal=\"rug\",\n",
        "                   color_discrete_sequence=['#EF554A']) # Optional: Customize color\n",
        "fig.update_layout(xaxis_title=\"Year of Birth\", yaxis_title=\"Frequency\")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "# 3. Count of Customers by Country\n",
        "fig = px.bar(df_filtered, x=\"Country\", title=\"Count of Customers by Country\",\n",
        "             color_discrete_sequence=['#00AC56']) # Optional: Customize color\n",
        "fig.update_layout(xaxis_title=\"Country\", yaxis_title=\"Count\")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "# 4. Relationship between Income and Year of Birth\n",
        "fig = px.scatter(df_filtered, x=\"Income\", y=\"Year_Birth\", title=\"Income vs Year of Birth\",\n",
        "                 color_discrete_sequence=['#AB63FA']) # Optional: Customize color\n",
        "fig.update_layout(xaxis_title=\"Income\", yaxis_title=\"Year of Birth\")\n",
        "fig.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77816a0",
      "metadata": {
        "id": "b77816a0"
      },
      "source": [
        "## **3. Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create new features based on existing ones, such as by combining \"purchase frequencies\" & \"creating customer segments\" that might help improve the model's performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "q-LzZ0QxQ5E1"
      },
      "id": "q-LzZ0QxQ5E1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Combining Purchase Frequencies**\n",
        "\n",
        "\n",
        "**Total Purchases:** We first calculate the total number of purchases made by each customer across all channels (web, catalog, and store) and store it in a new column called \"TotalPurchases\".\n",
        "\n",
        "**Purchase Frequency Category:** Then we use the \"pd.cut function\" to \"categorize customers into different purchase frequency segments\" based on their \"TotalPurchases\".\n",
        "\n",
        "The bins parameter defines the ranges for each category, and the labels parameter assigns descriptive labels to those categories.\n"
      ],
      "metadata": {
        "id": "Oc015jC1Ro_R"
      },
      "id": "Oc015jC1Ro_R"
    },
    {
      "source": [
        "# Calculating total purchase frequency across all channels\n",
        "df_filtered['TotalPurchases'] = df_filtered['NumWebPurchases'] + df_filtered['NumCatalogPurchases'] + df_filtered['NumStorePurchases']\n",
        "\n",
        "# Creating the \"Total Amount column\"\n",
        "df_filtered['Total Amount'] = df_filtered['MntWines'] + df_filtered['MntFruits'] + df_filtered['MntMeatProducts'] + df_filtered['MntFishProducts'] + df_filtered['MntSweetProducts'] + df_filtered['MntGoldProds']\n",
        "\n",
        "\n",
        "# Creating new feature representing \"purchase frequency category\"\n",
        "df_filtered['PurchaseFrequencyCategory'] = pd.cut(df_filtered['TotalPurchases'], bins=[0, 5, 10, 15, float('inf')], labels=['Low', 'Medium', 'High', 'Very High'])\n",
        "df_filtered\n",
        "\n",
        "# PurchaseFrequencyCategory- contains 6 missing values, for them adding a new category [No Purchases] to the existing categories.\n",
        "df_filtered['PurchaseFrequencyCategory'] = df_filtered['PurchaseFrequencyCategory'].cat.add_categories('No Purchases')\n",
        "df_filtered['PurchaseFrequencyCategory'] = df_filtered['PurchaseFrequencyCategory'].fillna('No Purchases')\n",
        "\n",
        "df_filtered\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7D-Hod9NRJDT"
      },
      "id": "7D-Hod9NRJDT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PurchaseFrequencyCategory**\n",
        "This column categorizes customers based on their total purchases. Since it's derived from **numerical features** (NumWebPurchases, NumCatalogPurchases, NumStorePurchases), the missing values are due to **customers having zero purchases across all channels.**\n"
      ],
      "metadata": {
        "id": "gmVZ2ejuNgGS"
      },
      "id": "gmVZ2ejuNgGS"
    },
    {
      "cell_type": "code",
      "source": [
        "# no more missing values in PurchaseFrequencyCategory\n",
        "df_filtered.isnull().sum()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O0vy0YyHNhqu"
      },
      "id": "O0vy0YyHNhqu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Creating Customer Segments using RFM Analysis**\n",
        "\n",
        "RFM analysis stands for Recency, Frequency, and Monetary value. A popular method for customer segmentation.\n",
        "\n",
        "**Quantiles:** We use pd.qcut to divide customers into quartiles (4 segments) based on their RFM values. This assigns a quartile value (0-3) to each customer for each RFM metric.\n",
        "\n",
        "**Combining Quartiles:** then we concatenate the quartile values to create an RFM segment code for each customer.\n",
        "\n",
        "**Display:** Then we display the RFM segment codes to check the results.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXSPrc7HRySu"
      },
      "id": "rXSPrc7HRySu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency: TotalPurchases (calculated above)\n",
        "\n",
        "\n",
        "# Creating quantiles for RFM values\n",
        "df_filtered['R_Quartile'] = pd.qcut(df_filtered['Recency'], 4, labels=False)\n",
        "df_filtered['F_Quartile'] = pd.qcut(df_filtered['TotalPurchases'], 4, labels=False)\n",
        "df_filtered['M_Quartile'] = pd.qcut(df_filtered['Total Amount'], 4, labels=False)\n",
        "\n",
        "# Combine RFM quartiles to create customer segments\n",
        "df_filtered['RFM_Segment'] = df_filtered['R_Quartile'].astype(str) + df_filtered['F_Quartile'].astype(str) + df_filtered['M_Quartile'].astype(str)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df_filtered[['RFM_Segment']].head()\n"
      ],
      "metadata": {
        "id": "b7KIpAOtTDfo"
      },
      "id": "b7KIpAOtTDfo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now we further analyze the segment characteristics and assigning meaningful labels, to gain better understanding of our customer base and tailor our marketing strategies accordingly.\n",
        "\n",
        "* For example, we can target **\"High-Value Customers\" with exclusive offers** or **\"Churned Customers\" with re-engagement campaigns**.\n"
      ],
      "metadata": {
        "id": "bvR3QDOXat3y"
      },
      "id": "bvR3QDOXat3y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Analyze RFM Segment Characteristics**\n",
        "\n",
        "* Here we groups customers based on their RFM segments and calculates the average values for features like Recency, Total Purchases, and Total Amount within each segment.\n",
        "\n",
        "* This helps us understand the distinct characteristics of each segment. For example, a segment with high average Recency, low average Frequency, and low average Monetary value might indicate \"Churned Customers.\""
      ],
      "metadata": {
        "id": "qnKU-jNlbZEB"
      },
      "id": "qnKU-jNlbZEB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Group customers by RFM segment and calculate average values for relevant features\n",
        "segment_analysis = df_filtered.groupby('RFM_Segment').agg({\n",
        "    'Recency': 'mean',\n",
        "    'TotalPurchases': 'mean',\n",
        "    'Total Amount': 'mean',\n",
        "    # We can add other relevant features\n",
        "})\n",
        "\n",
        "# Display the segment analysis results\n",
        "segment_analysis\n"
      ],
      "metadata": {
        "id": "nxSh0AvFVPl5"
      },
      "id": "nxSh0AvFVPl5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Assign Meaningful Labels**\n",
        "\n",
        "* defines a dictionary segment_labels to map RFM segment codes (e.g., '000', '001') to descriptive labels (e.g., 'Churned Customers', 'At Risk Customers').\n",
        "\n",
        "* It then uses the map function to create a new column RFM_Segment_Label in the DataFrame, assigning the corresponding labels based on the RFM segment codes.\n",
        "\n",
        "* By analyzing the segment characteristics and assigning meaningful labels, we can gain better understanding of our customer base and tailor the marketing strategies/ camapigns accordingly."
      ],
      "metadata": {
        "id": "FznbHiPvbj7H"
      },
      "id": "FznbHiPvbj7H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dictionary to map RFM segment codes to labels\n",
        "\n",
        "segment_labels = {\n",
        "    '000': 'Churned Customers',\n",
        "    '001': 'At Risk Customers',\n",
        "    '002': 'Low-Value Customers',\n",
        "    '003': 'Potential Loyalists',\n",
        "    '010': 'About to Sleep',\n",
        "    '011': 'Promising',\n",
        "    '012': 'Need Attention',\n",
        "    '013': 'Loyal Customers',\n",
        "    '020': 'Hibernating',\n",
        "    '021': 'High-Value Customers',\n",
        "    '022': 'Potential Churners',\n",
        "    '023': 'Champions',\n",
        "    '030': 'Lost',\n",
        "    '031': 'Cannot Lose Them',\n",
        "    '032': 'Recent Customers',\n",
        "    '033': 'Top Customers',\n",
        "\n",
        "    '100': 'Low-Value Frequent',\n",
        "    '101': 'Potential High-Value',\n",
        "    '102': 'Need Nurturing',\n",
        "    '103': 'Growing Champions',\n",
        "    '110': 'High-Value Frequent',\n",
        "    '111': 'Top Spenders',\n",
        "    '112': 'Recent High-Value',\n",
        "    '113': 'Elite Customers',\n",
        "    '120': 'Churned Frequent',\n",
        "    '121': 'At Risk Frequent',\n",
        "    '122': 'Low-Value Frequent',\n",
        "    '123': 'Potential Loyalists Frequent',\n",
        "    '130': 'About to Sleep Frequent',\n",
        "    '131': 'Promising Frequent',\n",
        "    '132': 'Need Attention Frequent',\n",
        "    '133': 'Loyal Customers Frequent',\n",
        "\n",
        "    '200': 'Hibernating Frequent',\n",
        "    '201': 'High-Value Frequent',\n",
        "    '202': 'Potential Churners Frequent',\n",
        "    '203': 'Champions Frequent',\n",
        "    '210': 'Lost Frequent',\n",
        "    '211': 'Cannot Lose Them Frequent',\n",
        "    '212': 'Recent Frequent',\n",
        "    '213': 'Top Frequent',\n",
        "    '220': 'Low-Value Frequent',\n",
        "    '221': 'Potential High-Value',\n",
        "    '222': 'Need Nurturing Frequent',\n",
        "    '223': 'Growing Frequent',\n",
        "    '230': 'High-Value Frequent',\n",
        "    '231': 'Top Spenders Frequent',\n",
        "    '232': 'Recent Frequent',\n",
        "    '233': 'Elite Frequent',\n",
        "\n",
        "    '300': 'Churned Recent',\n",
        "    '301': 'At Risk Recent',\n",
        "    '302': 'Low-Value Recent',\n",
        "    '303': 'Potential Loyalists Recent',\n",
        "    '310': 'About to Sleep Recent',\n",
        "    '311': 'Promising Recent',\n",
        "    '312': 'Need Attention Recent',\n",
        "    '313': 'Loyal Customers Recent',\n",
        "    '320': 'Hibernating Recent',\n",
        "    '321': 'High-Value Recent',\n",
        "    '322': 'Potential Churners Recent',\n",
        "    '323': 'Champions Recent',\n",
        "    '330': 'Lost Recent',\n",
        "    '331': 'Cannot Lose Them Recent',\n",
        "    '332': 'Recent Customers',\n",
        "    '333': 'Top Customers'\n",
        "}\n",
        "\n",
        "# Added a new column \"segment labels\" to df_filtered\n",
        "df_filtered['RFM_Segment_Label'] = df_filtered['RFM_Segment'].map(segment_labels)\n",
        "\n",
        "df_filtered[['RFM_Segment', 'RFM_Segment_Label']].head()\n"
      ],
      "metadata": {
        "id": "nVWl73qubka7"
      },
      "id": "nVWl73qubka7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a4401b3",
      "metadata": {
        "id": "9a4401b3"
      },
      "source": [
        "## **4.Data Analysis &  Model Building**\n",
        "\n",
        "### **4.1 Data Analysis**\n",
        "\n",
        "Now we define 5 business questions for our objective which is to analyze the  **Marketing Campaign Effectiveness**.\n",
        "\n",
        "\n",
        "**1. Customer Segmentation:** \"Can we identify distinct customer segments based on their purchasing behavior and demographics?\" (This would lead to RFM analysis, clustering etc)\n",
        "\n",
        "**2. Predictive Modeling:** \"Can we predict which customers are most likely to respond to a future campaign based on their past behavior?\" (This would involve building a classification model.)\n",
        "\n",
        "\n",
        "**3. Campaign Optimization:** \"What factors have the strongest influence on campaign success?\" (This would require statistical testing or feature importance analysis).\n",
        "\n",
        "**4.Channel Performance:** \"Which channels (web, catalog, store) are most effective for different customer segments?\" (This could involve segmenting by channel usage and comparing conversion rates.)\n",
        "\n",
        "**5.Product Recommendations:** \"Can we identify products that are frequently purchased together and use this information for recommendations?\" (This would involve association rule mining or market basket analysis.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "### **4.2 Model Building**\n",
        "\n",
        "* Then we explore different model types (e.g., logistic regression, decision trees, random forests) and evaluate them.\n",
        "\n",
        "* Then we tune with hyperparameters using GridSearchCV to optimize our models."
      ],
      "metadata": {
        "id": "AVkNi4sG7RK0"
      },
      "id": "AVkNi4sG7RK0"
    },
    {
      "cell_type": "markdown",
      "id": "7d47862e",
      "metadata": {
        "id": "7d47862e"
      },
      "source": [
        "### **Q1. Customer Segmentation: Identify distinct customer segments based on their purchasing behavior and demographics?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* this part was done previously done in **3. Feature Engineering** section.\n",
        "\n",
        "* **RFM analysis** uses purchasing behavior and demographics to segment customers.\n",
        "\n",
        "* **Quantiles and Segmentation:** calculated quantiles for each RFM metric and combines them to create distinct customer segments.\n",
        "\n",
        "  These segments are then labeled with descriptive names (e.g., \"Churned Customers,\" \"Loyal Customers\") based on their RFM characteristics.\n",
        "---------------------------------------\n",
        "\n",
        "* **Additional part--** **Demographics:** Now we incorporate demographic data by including relevant columns (e.g., age, income, education) in our analysis and segmentation process.\n",
        "\n",
        "* For a more comprehensive understanding of customer segments based on both behavior and demographics.\n"
      ],
      "metadata": {
        "id": "YfwlJhF3-wJn"
      },
      "id": "YfwlJhF3-wJn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating quantiles for RFM values\n",
        "df_filtered['R_Quartile'] = pd.qcut(df_filtered['Recency'], 4, labels=False)\n",
        "df_filtered['F_Quartile'] = pd.qcut(df_filtered['TotalPurchases'], 4, labels=False)\n",
        "df_filtered['M_Quartile'] = pd.qcut(df_filtered['Total Amount'], 4, labels=False)\n",
        "\n",
        "# Combine RFM quartiles to create customer segments\n",
        "df_filtered['RFM_Segment'] = df_filtered['R_Quartile'].astype(str) + df_filtered['F_Quartile'].astype(str) + df_filtered['M_Quartile'].astype(str)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df_filtered[['RFM_Segment']].head()\n",
        "\n",
        "df_filtered\n",
        "\n",
        "# Creating a dictionary to map RFM segment codes to labels\n",
        "segment_labels = {\n",
        "    '000': 'Churned Customers',\n",
        "    '001': 'At Risk Customers',\n",
        "    '002': 'Low-Value Customers',\n",
        "    '003': 'Potential Loyalists',\n",
        "    '010': 'About to Sleep',\n",
        "    '011': 'Promising',\n",
        "    '012': 'Need Attention',\n",
        "    '013': 'Loyal Customers',\n",
        "    '020': 'Hibernating',\n",
        "    '021': 'High-Value Customers',\n",
        "    '022': 'Potential Churners',\n",
        "    '023': 'Champions',\n",
        "    '030': 'Lost',\n",
        "    '031': 'Cannot Lose Them',\n",
        "    '032': 'Recent Customers',\n",
        "    '033': 'Top Customers',\n",
        "\n",
        "    '100': 'Low-Value Frequent',\n",
        "    '101': 'Potential High-Value',\n",
        "    '102': 'Need Nurturing',\n",
        "    '103': 'Growing Champions',\n",
        "    '110': 'High-Value Frequent',\n",
        "    '111': 'Top Spenders',\n",
        "    '112': 'Recent High-Value',\n",
        "    '113': 'Elite Customers',\n",
        "    '120': 'Churned Frequent',\n",
        "    '121': 'At Risk Frequent',\n",
        "    '122': 'Low-Value Frequent',\n",
        "    '123': 'Potential Loyalists Frequent',\n",
        "    '130': 'About to Sleep Frequent',\n",
        "    '131': 'Promising Frequent',\n",
        "    '132': 'Need Attention Frequent',\n",
        "    '133': 'Loyal Customers Frequent',\n",
        "\n",
        "    '200': 'Hibernating Frequent',\n",
        "    '201': 'High-Value Frequent',\n",
        "    '202': 'Potential Churners Frequent',\n",
        "    '203': 'Champions Frequent',\n",
        "    '210': 'Lost Frequent',\n",
        "    '211': 'Cannot Lose Them Frequent',\n",
        "    '212': 'Recent Frequent',\n",
        "    '213': 'Top Frequent',\n",
        "    '220': 'Low-Value Frequent',\n",
        "    '221': 'Potential High-Value',\n",
        "    '222': 'Need Nurturing Frequent',\n",
        "    '223': 'Growing Frequent',\n",
        "    '230': 'High-Value Frequent',\n",
        "    '231': 'Top Spenders Frequent',\n",
        "    '232': 'Recent Frequent',\n",
        "    '233': 'Elite Frequent',\n",
        "\n",
        "    '300': 'Churned Recent',\n",
        "    '301': 'At Risk Recent',\n",
        "    '302': 'Low-Value Recent',\n",
        "    '303': 'Potential Loyalists Recent',\n",
        "    '310': 'About to Sleep Recent',\n",
        "    '311': 'Promising Recent',\n",
        "    '312': 'Need Attention Recent',\n",
        "    '313': 'Loyal Customers Recent',\n",
        "    '320': 'Hibernating Recent',\n",
        "    '321': 'High-Value Recent',\n",
        "    '322': 'Potential Churners Recent',\n",
        "    '323': 'Champions Recent',\n",
        "    '330': 'Lost Recent',\n",
        "    '331': 'Cannot Lose Them Recent',\n",
        "    '332': 'Recent Customers',\n",
        "    '333': 'Top Customers'\n",
        "}\n",
        "\n",
        "\n",
        "# Added a new column \"segment labels\" to df_filtered\n",
        "df_filtered['RFM_Segment_Label'] = df_filtered['RFM_Segment'].map(segment_labels)\n",
        "\n",
        "df_filtered[['RFM_Segment', 'RFM_Segment_Label']].head()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "65bSPuyF6S81"
      },
      "id": "65bSPuyF6S81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped customers by RFM segment and calculated average values for relevant features\n",
        "segment_analysis = df_filtered.groupby(['RFM_Segment_Label', 'Education', 'Marital_Status', 'Country']).agg({\n",
        "    'Recency': 'mean',\n",
        "    'TotalPurchases': 'mean',\n",
        "    'Total Amount': 'mean',\n",
        "    'AcceptedCmp1': 'mean',  # Campaign acceptance\n",
        "    'AcceptedCmp2': 'mean',\n",
        "    'AcceptedCmp3': 'mean',\n",
        "    'AcceptedCmp4': 'mean',\n",
        "    'AcceptedCmp5': 'mean',\n",
        "    'NumWebVisitsMonth': 'mean',  # Web visits\n",
        "    'MntWines': 'mean',  # Product spending\n",
        "    'MntFruits': 'mean',\n",
        "    'MntMeatProducts': 'mean',\n",
        "    'MntFishProducts': 'mean',\n",
        "    'MntSweetProducts': 'mean',\n",
        "    'MntGoldProds': 'mean',\n",
        "    'NumWebPurchases': 'mean',  # Channel preference\n",
        "    'NumCatalogPurchases': 'mean',\n",
        "    'NumStorePurchases': 'mean',\n",
        "    'Complain': 'mean'  # Complaints\n",
        "})\n",
        "\n",
        "segment_analysis\n"
      ],
      "metadata": {
        "id": "Z7V7yDxTBR9y"
      },
      "id": "Z7V7yDxTBR9y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.Visualization**"
      ],
      "metadata": {
        "id": "fZCof08b8erg"
      },
      "id": "fZCof08b8erg"
    },
    {
      "cell_type": "code",
      "source": [
        "# Using matplotlib\n",
        "\n",
        "#countplot\n",
        "# 1. Distribution of RFM Segment Labels\n",
        "\n",
        "# Count occurrences of each segment label\n",
        "segment_counts = df_filtered['RFM_Segment_Label'].value_counts().reset_index()\n",
        "segment_counts.columns = ['RFM_Segment_Label', 'Count']\n",
        "\n",
        "# Create interactive bar chart\n",
        "fig = px.bar(segment_counts, x='RFM_Segment_Label', y='Count',\n",
        "             title='Distribution of Customer Segments (RFM)')\n",
        "fig.update_layout(\n",
        "    xaxis_title='RFM Segment Label',\n",
        "    yaxis_title='Count',\n",
        "    xaxis={\n",
        "        'categoryorder': 'total descending',\n",
        "        'tickangle': -45,  # Rotate labels by -45 degrees\n",
        "        'tickfont': {'size': 10}  # font size\n",
        "    },\n",
        "    autosize=False,  # Disable autosizing\n",
        "    width=1000  # Set width to match Seaborn plot\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#barplot\n",
        "# 2. Average Total Amount Spent by RFM Segment\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "segment_analysis_reset = segment_analysis.reset_index()  # Reset index if needed\n",
        "\n",
        "fig = px.bar(segment_analysis_reset, x='RFM_Segment_Label', y='Total Amount',\n",
        "             title='Average Total Amount Spent by Customer Segment',\n",
        "             color_discrete_sequence=['#ff7f0e'])  # Optional: Customize color\n",
        "fig.update_layout(\n",
        "    xaxis_title='RFM Segment Label',\n",
        "    yaxis_title='Average Total Amount Spent',\n",
        "    xaxis={\n",
        "        'categoryorder': 'total descending',\n",
        "        'tickangle': -45,  # Rotate labels by -45 degrees\n",
        "        'tickfont': {'size': 10}  # Reduce font size\n",
        "    },\n",
        "    autosize=False,  # Disable autosizing\n",
        "    width=1000  # Set width to match Seaborn plot\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#barplot\n",
        "# 3. Average Total Purchases by RFM Segment and Education\n",
        "\n",
        "# Calculated average total purchases for each segment and education level\n",
        "segment_purchases = df_filtered.groupby(['RFM_Segment_Label', 'Education'])['TotalPurchases'].mean().reset_index()\n",
        "\n",
        "# Created interactive bar chart\n",
        "fig = px.bar(segment_purchases, x='RFM_Segment_Label', y='TotalPurchases', color='Education',\n",
        "             title='Average Total Purchases by Customer Segment and Education')\n",
        "fig.update_layout(\n",
        "    xaxis_title='RFM Segment Label',\n",
        "    yaxis_title='Average Total Purchases',\n",
        "    xaxis={\n",
        "        'categoryorder': 'total descending',\n",
        "        'tickangle': -45,  # Rotate labels by -45 degrees\n",
        "        'tickfont': {'size': 10}  #font size\n",
        "    },\n",
        "    autosize=False,  # Disable autosizing\n",
        "    width=1000  # Set width to match Seaborn plot\n",
        ")\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "1Q6K1UjLGgLP"
      },
      "id": "1Q6K1UjLGgLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n"
      ],
      "metadata": {
        "id": "C4kIpgip8wnE"
      },
      "id": "C4kIpgip8wnE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "43689a1a",
      "metadata": {
        "id": "43689a1a"
      },
      "source": [
        "### **SUMMARY**\n",
        "    "
      ]
    },
    {
      "cell_type": "raw",
      "id": "c23807c7",
      "metadata": {
        "id": "c23807c7"
      },
      "source": [
        "**1. RFM Segment Distribution:** shows the distribution of customers across various RFM segments (e.g., \"Churned Customers,\" \"Loyal Customers,\" etc.), giving an overview of their purchasing behavior.\n",
        "\n",
        "\n",
        "**2. Spending Behavior:** average total amount spent by each customer segment, highlighting differences in spending patterns.\n",
        "\n",
        "**3. Purchases and Demographics:**  RFM segments with education levels to display the average total purchases made by each segment within different education groups. This provides insights into how demographics influence purchasing behavior within each segment.\n",
        "\n",
        "\n",
        "* By analyzing these visualizations, we can identify distinct customer segments and understand their behavior to design targeted marketing strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f657db59",
      "metadata": {
        "id": "f657db59"
      },
      "source": [
        "### **Q2. Predictive Modeling: Can we predict which customers are most likely to respond to a future campaign based on their past behavior?**"
      ]
    },
    {
      "source": [
        "# Model Building and Evaluation using GridSearchCV for hyperparameter tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier # Import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Importing necessary modules\n",
        "\n",
        "# 'Response' is the target variable\n",
        "X = df.drop('Response', axis=1)\n",
        "y = df['Response']\n",
        "\n",
        "# 1. Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# 2. Get a list of categorical features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 3. Fit and transform the categorical features using LabelEncoder\n",
        "for feature in categorical_features:\n",
        "    X[feature] = label_encoder.fit_transform(X[feature])\n",
        "\n",
        "# 4. Create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 5. Fit and transform the numerical features using StandardScaler\n",
        "numerical_features = X.select_dtypes(include=['number']).columns\n",
        "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check for infinite values in X_train\n",
        "np.isinf(X_train).any() # This line was moved here to be after X_train is defined.\n",
        "\n",
        "# Check for NaN values in X_train\n",
        "print(np.isnan(X_train).any())\n",
        "\n",
        "# Define models and parameter grids for GridSearchCV\n",
        "models = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {'C': [1]}\n",
        "    },\n",
        "    'RandomForestClassifier': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params': {'n_estimators': [300], 'max_depth': [10]}\n",
        "    },\n",
        "    'DecisionTreeClassifier': {  # Added DecisionTreeClassifier\n",
        "        'model': DecisionTreeClassifier(),\n",
        "        'params': {'max_depth': [5], 'min_samples_split': [2], 'min_samples_leaf': [1]}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model using GridSearchCV\n",
        "for model_name, model_params in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    clf = GridSearchCV(model_params['model'], model_params['params'], cv=5)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"Best parameters: {clf.best_params_}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
        "\n",
        "# all 3 models tuned on best parameters\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-fgFocL4gOAM"
      },
      "id": "-fgFocL4gOAM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6af1e9ba",
      "metadata": {
        "id": "6af1e9ba"
      },
      "source": [
        "* We trained and evaluated 3 models (Logistic Regression, Random Forest, and Decision Tree) by using GridSearchCV for hyperparameter optimization and fine tune the models with the \"Best parameters\"."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our objective is to **analyze the marketing campaign effectiveness and predicting customer response**,  so we will choose **Random Forest Classifier** & here are the reasons why we choose RFC:\n",
        "\n",
        "1. **Higher Accuracy:**  compared to Logistic Regression and Decision Trees.\n",
        "\n",
        "  * We observed accuracy of ~89% with Random Forest.\n",
        "\n",
        "\n",
        "2. **Handles Non-linearity:** Unlike Logistic Regression, it effectively captures non-linear relationships between features and the target variable (customer response).\n",
        "\n",
        "3. **Robustness to Overfitting:** less prone to overfitting than Decision Trees due to its ensemble nature, averaging predictions from multiple trees.\n",
        "\n",
        "4. **Feature Importance:** Provides insights into the importance of different features in predicting customer response, guiding marketing strategy.\n",
        "\n",
        "5. **Handles Missing Values:** It inherently handles missing values without requiring imputation, which can be advantageous if you have incomplete data."
      ],
      "metadata": {
        "id": "f77YHRoKt9dw"
      },
      "id": "f77YHRoKt9dw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our project, the higher accuracy and robust nature of Random Forest makes it the preferred choice **to effectively analyze marketing campaign effectiveness and predict customer response**."
      ],
      "metadata": {
        "id": "2yy2iLj7vcIn"
      },
      "id": "2yy2iLj7vcIn"
    },
    {
      "cell_type": "raw",
      "id": "906cf1ee",
      "metadata": {
        "id": "906cf1ee"
      },
      "source": [
        " **Q2.Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2feb0a44",
      "metadata": {
        "id": "2feb0a44"
      },
      "outputs": [],
      "source": [
        "# We use bar plot to compare the predicted probabilities of response for different customer segments.\n",
        "\n",
        "\n",
        "# Predicting probabilities of response\n",
        "y_probs = clf.predict_proba(X_test)[:, 1]  # Probability of class 1 (response)\n",
        "\n",
        "# Get the RFM segment labels for the test set using the index of X_test\n",
        "rfm_segment_labels_test = df_filtered['RFM_Segment_Label'][X_test.index]\n",
        "\n",
        "# Create a DataFrame with predicted probabilities and RFM segment labels for the test set\n",
        "predictions_df = pd.DataFrame({'Probability': y_probs, 'RFM_Segment_Label': rfm_segment_labels_test})\n",
        "\n",
        "# Plot the average predicted probabilities for each RFM segment\n",
        "fig = px.bar(predictions_df, x='RFM_Segment_Label', y='Probability',\n",
        "             title='Predicted Probability of Response by Customer Segment',\n",
        "             color_discrete_sequence=['#636EFA'])  # Customize color if desired\n",
        "fig.update_layout(\n",
        "    xaxis_title='RFM Segment Label',\n",
        "    yaxis_title='Predicted Probability',\n",
        "    xaxis={\n",
        "        'categoryorder': 'total descending',\n",
        "        'tickangle': -45,  # Rotate labels by -45 degrees\n",
        "        'tickfont': {'size': 10}  # Reduce font size\n",
        "    },\n",
        "    autosize=False,  # Disable autosizing\n",
        "    width=1000  # Set width to match Seaborn plot\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d3a37d",
      "metadata": {
        "id": "82d3a37d"
      },
      "source": [
        "### **SUMMARY**\n",
        "    "
      ]
    },
    {
      "cell_type": "raw",
      "id": "1f4c202c",
      "metadata": {
        "id": "1f4c202c"
      },
      "source": [
        "* Predictive modeling using the **Random Forest Classifier** can identify customers most likely to respond to future campaigns based on their past behavior and demographics.\n",
        "\n",
        "* The visualization reveals that certain customer segments, such as **\"Top Customers\" and \"Champions,\"** exhibit **higher predicted probabilities of response**.\n",
        "\n",
        "* This information can be leveraged to target marketing efforts effectively and maximize campaign success.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed9eef7",
      "metadata": {
        "id": "7ed9eef7"
      },
      "source": [
        "### **Q3. Campaign Optimization: What factors have the strongest influence on campaign success?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* To determine the factors that have the strongest influence on campaign success, we can analyze the feature importance from the trained Random Forest Classifier model.\n",
        "\n",
        "* The feature importance scores indicate the relative contribution of each feature in \"predicting\" the **target variable (customer response).**\n"
      ],
      "metadata": {
        "id": "om6uXgffixxp"
      },
      "id": "om6uXgffixxp"
    },
    {
      "source": [
        "# Getting feature importance scores from the trained Random Forest model\n",
        "importances = clf.best_estimator_.feature_importances_\n",
        "\n",
        "# Created a DataFrame to store feature importances\n",
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7aR_NMt4uO5f"
      },
      "id": "7aR_NMt4uO5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8c340200",
      "metadata": {
        "id": "8c340200"
      },
      "source": [
        " **Q3. Visualization**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature importances using a bar plot\n",
        "fig = px.bar(feature_importances, x='Importance', y='Feature',\n",
        "             title='Feature Importance for Campaign Success Prediction',\n",
        "             orientation='h')  # Set orientation to horizontal\n",
        "fig.update_layout(xaxis_title='Importance Score', yaxis_title='Feature')\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "lh61jJ1XuI5v"
      },
      "id": "lh61jJ1XuI5v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The features with higher importance scores (AcceptedCmp5, Recency & AcceptedCmp3) have a **stronger influence on campaign success prediction**."
      ],
      "metadata": {
        "id": "4vqhS21hvbbO"
      },
      "id": "4vqhS21hvbbO"
    },
    {
      "cell_type": "markdown",
      "id": "f0d557e8",
      "metadata": {
        "id": "f0d557e8"
      },
      "source": [
        "### **SUMMARY**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* By analyzing the feature plot, we can identify the key factors that drive campaign success. This information can be used to optimize marketing strategies by focusing on the most influential factors.\n",
        "\n",
        "* e.g. **\"AcceptedCmp5, Recency & AcceptedCmp3\"** are the most important features, campaigns can be tailored to target customers who have made recent purchases and have a high total spending amount.\n"
      ],
      "metadata": {
        "id": "VSZiKh8juz8q"
      },
      "id": "VSZiKh8juz8q"
    },
    {
      "cell_type": "markdown",
      "id": "0b07425d",
      "metadata": {
        "id": "0b07425d"
      },
      "source": [
        "### **Q4. Channel Performance: Which channels (web, catalog, store) are most effective for different customer segments?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze channel performance for different customer segments, we follow 3 steps:\n",
        "\n",
        "\n",
        "**1. Group by Customer Segment and Channel:** Group df_filtered by \"RFM_Segment_Label\" and the purchase channel columns \"(NumWebPurchases, NumCatalogPurchases, NumStorePurchases)\".\n",
        "\n",
        "**2. Calculate Average Purchases per Channel:** Calculated the \"average number of purchases made through each channel\" for each \"customer segment\".\n",
        "\n",
        "**3. Compared Channel Performance:** Comparing the \"average purchases per channel across different customer segments\" to identify which \"channels are most effective for each segment\"."
      ],
      "metadata": {
        "id": "nJC-euu0w4FG"
      },
      "id": "nJC-euu0w4FG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91038fd0",
      "metadata": {
        "id": "91038fd0"
      },
      "outputs": [],
      "source": [
        "# Group by customer segment and channel, then calculated average purchases per channel\n",
        "channel_performance = df_filtered.groupby('RFM_Segment_Label')[['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases']].mean()\n",
        "\n",
        "channel_performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cecd0d",
      "metadata": {
        "id": "71cecd0d"
      },
      "source": [
        " **Q4. Visualization**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melted the DataFrame to create a long format for plotting\n",
        "channel_performance_melted = channel_performance.reset_index().melt(id_vars=['RFM_Segment_Label'], value_vars=['NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases'], var_name='Channel', value_name='Average Purchases')\n",
        "\n",
        "# Created a bar plot\n",
        "fig = px.bar(channel_performance_melted,\n",
        "             x='RFM_Segment_Label',\n",
        "             y='Average Purchases',\n",
        "             color='Channel',\n",
        "             title='Channel Performance by Customer Segment',\n",
        "             barmode='group')  # Use 'group' for grouped bars\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='RFM Segment Label',\n",
        "    yaxis_title='Average Purchases',\n",
        "    xaxis={\n",
        "        'categoryorder': 'total descending',\n",
        "        'tickangle': -45,\n",
        "        'tickfont': {'size': 10}\n",
        "    },\n",
        "    yaxis={\n",
        "        'dtick': 3  # Set the y-axis tick interval to 2\n",
        "    },\n",
        "    autosize=False,\n",
        "    width=1000  # Adjust width as needed\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "k2MuNwPxwYTs"
      },
      "id": "k2MuNwPxwYTs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The bar plot shows the average number of purchases made through each channel (web, catalog, store) for different customer segments.\n",
        "\n",
        "* This visualization helps us to identify the preferred channels for each segment."
      ],
      "metadata": {
        "id": "UJrOF2gCzNCw"
      },
      "id": "UJrOF2gCzNCw"
    },
    {
      "cell_type": "markdown",
      "id": "cdbf727e",
      "metadata": {
        "id": "cdbf727e"
      },
      "source": [
        "### **SUMMARY**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90157f77",
      "metadata": {
        "id": "90157f77"
      },
      "source": [
        "* By analyzing the channel performance data and visualizations, we can gain insights into which channels are most effective for different customer segments.\n",
        "\n",
        "* Then this information can be used to tailor marketing strategies and optimize channel allocation to maximize campaign effectiveness.\n",
        "\n",
        "* e.g. , we observe that **\"Champions, Loyal customers, potential loyalists & Top customers\"** prefer the **store & web channel**, so we can consider allocating more marketing resources to **\"in-store promotions\" & online advertising and personalized website experiences for them.**  for **this segment**.\n",
        "\n",
        "* On otherside, **\"catalog channel\"** is not performing well in various **customer segments \"About to Sleep, Churned customers, lost and need attention\"** campaigns for them can be customized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "854becb4",
      "metadata": {
        "id": "854becb4"
      },
      "source": [
        "### **Q5. Product Recommendations: Identify products that are frequently purchased together and use this information for recommendations?**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To identify products that are frequently purchased together, we can use **association rule mining** or **market basket analysis**.\n",
        "\n",
        "* In our case, we'll use the **apriori algorithm** from the mlxtend library.\n",
        "\n",
        "* This algorithm **finds frequent item sets (sets of products that are often purchased together)** and **generates association rules** (rules that suggest which products are likely to be purchased together).\n",
        "\n"
      ],
      "metadata": {
        "id": "bJc-ca9M3z6E"
      },
      "id": "bJc-ca9M3z6E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gODrHpEREHxR"
      },
      "outputs": [],
      "source": [
        "# Installed mlxtend library\n",
        "!pip install mlxtend --upgrade"
      ],
      "id": "gODrHpEREHxR"
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "# Selected relevant columns for market basket analysis\n",
        "basket_cols = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
        "basket_df = df_filtered[basket_cols]\n",
        "\n",
        "# Converted the basket data into a one-hot encoded format\n",
        "basket_encoded = basket_df.applymap(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Apply the Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(basket_encoded, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "# Filter rules with lift greater than 1 and confidence greater than 0.5\n",
        "filtered_rules = rules[(rules['lift'] > 1) & (rules['confidence'] > 0.5)]\n",
        "\n",
        "# Displaying filtered rules\n",
        "filtered_rules\n"
      ],
      "metadata": {
        "id": "2IMbC9-q4oe5"
      },
      "id": "2IMbC9-q4oe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. Visualization**"
      ],
      "metadata": {
        "id": "Ok52j_7t4Uom"
      },
      "id": "Ok52j_7t4Uom"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import networkx as nx\n",
        "\n",
        "# Created a directed graph to represent the association rules\n",
        "graph = nx.DiGraph()\n",
        "\n",
        "# Added nodes (products) to the graph\n",
        "for product in filtered_rules['antecedents'].unique():\n",
        "    graph.add_node(list(product)[0])  #only one antecedent per rule\n",
        "\n",
        "# Adding edges (rules) to the graph\n",
        "for index, row in filtered_rules.iterrows():\n",
        "    antecedent = list(row['antecedents'])[0]\n",
        "    consequent = list(row['consequents'])[0]\n",
        "    graph.add_edge(antecedent, consequent, weight=row['lift'])\n",
        "\n",
        "# Draw the graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "pos = nx.spring_layout(graph)\n",
        "nx.draw(graph, pos, with_labels=True, node_size=1500, node_color=\"skyblue\", font_size=10, font_weight=\"bold\")\n",
        "nx.draw_networkx_edge_labels(graph, pos, edge_labels={(u, v): f\"{w:.2f}\" for u, v, w in graph.edges(data='weight')}, font_size=8)\n",
        "plt.title(\"Product Association Rules\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "om3VnNNf4YDH"
      },
      "id": "om3VnNNf4YDH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e65274a5",
      "metadata": {
        "id": "e65274a5"
      },
      "source": [
        "### **SUMMARY**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9adcba74",
      "metadata": {
        "id": "9adcba74"
      },
      "source": [
        "* Above we **identified** the **products** that are **frequently purchased together** using **association rule mining** with the **apriori algorithm.**\n",
        "\n",
        "* The **visualization** presents **these associations **as a **directed graph**, where **nodes represent products and edges represent rules**.\n",
        "\n",
        "* This **key information** can be **used to make product recommendations**, such as suggesting wines to customers who have purchased meat products.\n",
        "\n",
        "* By **understanding these patterns**, **businesses can tailor marketing strategies** and **increase sales by offering relevant product bundles or recommendations.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a7fbc3",
      "metadata": {
        "id": "c4a7fbc3"
      },
      "source": [
        "## **5. Conclusion & Proposed Solutions:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Marketing Campaign Effectiveness Analysis**\n",
        "\n",
        "Based on a thorough analysis of customer demographics, purchasing behavior, and campaign responses, this project reveals key insights for improving campaign performance:"
      ],
      "metadata": {
        "id": "0-0OMUwD77mJ"
      },
      "id": "0-0OMUwD77mJ"
    },
    {
      "cell_type": "markdown",
      "id": "995258c9",
      "metadata": {
        "id": "995258c9"
      },
      "source": [
        "* Based on our analysis, the following **key insights** were identified:\n",
        "\n",
        "    - **Insight 1:** High-value and loyal customer segments demonstrate the strongest response rates to marketing campaigns. (Based on RFM analysis).\n",
        "   \n",
        "    - **Insight 2:** \"Store and web channels\"\n",
        "     are the most effective channels for reaching and engaging high-value and loyal customers. (Based on channel performance analysis).\n",
        "\n",
        "    - **Insight 3:** Marketing campaigns (Cmp3 and Cmp5) have been successful in driving customer response. (Based on feature importance analysis).\n",
        "\n",
        "\n",
        "* Proposed **solutions** to improve marketing campaign effectiveness:\n",
        "\n",
        "    -  **Solution 1:** Focus on customizing marketing campaigns to target high-value and loyal customer segments, maximizing their ROI. (Based on RFM analysis, feature importance).\n",
        "\n",
        "    -  **Solution 2:** Prioritize marketing efforts on store and web channels for broader reach and higher conversion. (Based on channel performance analysis).\n",
        "\n",
        "    -  **Solution 3:** Continue to leverage successful campaign strategies from Cmp3 and Cmp5, adapting and improving them based on insights. (Based on feature importance analysis)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "*  These **data-driven solutions** aim to **enhance campaign targeting, channel optimization** and overall **effectiveness**, ultimately driving **improved business outcomes.**\n",
        "\n",
        "------------------------------------------------------"
      ],
      "metadata": {
        "id": "avZkT9Xq96LM"
      },
      "id": "avZkT9Xq96LM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Areas for Improvement:**\n",
        "\n",
        "* This project was completed in 2 days, with working schedule of 7 hours a day.\n",
        "\n",
        "* Mentioned below are the areas for improvements.\n"
      ],
      "metadata": {
        "id": "ddgstiuL-ty_"
      },
      "id": "ddgstiuL-ty_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Model Interpretability:**\n",
        "\n",
        "* Can provide more interpretation of the selected model (Random Forest Classifier).\n",
        "\n",
        "* By Considering techniques like SHAP values or partial dependence plots to understand how the model makes predictions and which features are most influential."
      ],
      "metadata": {
        "id": "So347Qh2_o5T"
      },
      "id": "So347Qh2_o5T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Handling Outliers:**\n",
        "* some potential outliers in the data but was not  explicitly addressed how they are handled.\n",
        "\n",
        "* By using outlier detection and treatment methods to improve model robustness."
      ],
      "metadata": {
        "id": "hPrmxCQ4_Z09"
      },
      "id": "hPrmxCQ4_Z09"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Data Scaling:**\n",
        "* We didn't mention data scaling, which is important for some machine learning models.\n",
        "\n",
        "* scaling numerical features using techniques like standardization or normalization."
      ],
      "metadata": {
        "id": "bQxlFkPa_eMe"
      },
      "id": "bQxlFkPa_eMe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. A/B Testing:**\n",
        "\n",
        "* We could include additional tests such as A/B testing to **validate** the **effectiveness of the proposed solutions in real-world scenarios**.\n"
      ],
      "metadata": {
        "id": "6ZYvIYDhAs_X"
      },
      "id": "6ZYvIYDhAs_X"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}